---
layout: default
title: Textmapper &middot; Documentation
kind: documentation
---

# Language Reference

## Introduction

The textmapper input file contains definitions of the lexer and parser as well as various options affecting the generation output. Either the parser or lexer section can be omitted to get only the lexer class or the parser with a prepared stub for a handwritten lexer.

The source text is a sequence of Unicode characters. By default, it is stored in a file with the extension .tm which is represented in the UTF-8 encoding.

Whitespaces (including line breaks) have no special meaning, and are used only as token separators. A single-line comment starts with a hash character (#). Any case-sensitive sequence of alphanumeric or underscore characters starting with a non-digit can be an identifier. It is also possible to use a dash in the middle, as in many reference grammars. Another possible form of an identifier is a sequence of characters in single quotes (').

## Options

The only required generation option specifies a target language for the output. Semantic actions and associated value types are considered to be in that language. Other options and their respective defaults are defined by the templates for the output language. Option values are checked to ensure they meet the definition type.

	# target language is Java, plus we need an AST
	lang = "java"
	genast = true

	# ... lexer specification
	# ... parser

The list of available options can be found in the documentation for the particular target language.

## Lexer

A lexical analyzer (lexer, scanner) is a component which breaks an input stream of characters into tokens (lexemes). The lexer specification consists of a set of rules. Each rule maps a lexical pattern to a terminal symbol, with the option of adding attributes and associated code. The generated lexer returns tokens one by one (in order of their appearance in the input), identifying them by applying the rule with the longest matching lexical pattern (i.e. `/==/` wins over `/=/`). On every successful match of a rule with associated code, the code is executed. The lexer generated by Textmapper can accept a true Unicode stream (when supported by the templates for the target language).

	# <token identifier>: <regular expression> [<attributes>] [<code>]
	IntegerConstant:  /0|[1-9][0-9]+/		{ $value = Integer.parseInt(current()); }

Lexemes marked with the _(space)_ attribute are excluded from the stream.

	# skip them
	WhiteSpace:   /[\n\r\t ]+/   (space)
	comment:      /#.*(\r?\n)?/  (space)

There is one predefined symbol **_eoi_**, meaning end-of-input. It is returned automatically when the end of the stream is reached. You can define you own lexical patterns for _eoi_ though.

	# treat Ctrl-Z as end-of-input, see http://en.wikipedia.org/wiki/Control-Z
	eoi: /\x1a/

It is possible to extract a valid part of a regular expression into a reusable named pattern.

	digit = /[0-9]/
	IntegerConstant: /{digit}+/

By omitting a lexical pattern, you can introduce a terminal symbol without a lexer rule. For example, adding the **_error_** terminal turns on the error recovery mechanism in the parser (see below).

	# a marker of the broken part of the stream
	error:

Mapping an input string to a terminal can be handled by the associated code.

	# some of the identifiers are types
	TYPE:
	ID:   /[a-zA-Z][a-zA-Z_0-9]*/   { if (isType($token)) $token = Lexemes.TYPE; }

## Associated values

During the parsing process, each symbol can optionally hold an associated value. Different symbols can have values of different types. The type can be specified in parentheses next to the symbol name. For example, IntegerConstant represents any number in the code, while the value of the number is usually attached to the symbol as the associated data.

	IntegerConstant (Integer): /[0-9]+/

By default, the associated value is null (nil, NULL, 0, etc., depending on the target language and type). To compute it for a terminal, add a semantic action to the lexer rule. "$value" is an alias for the associated value variable of the current terminal under construction.

	IntegerConstant (int): /[0-9]+/ { $value = Integer.parseInt(current()); }

When the string type is chosen for a terminal, the matched text is taken as the default associated value. Semantic actions can override this default value (to perform decoding, for example).

	# value is taken from the parsed text as is
	ID (String): /[a-z]+/

## Lexer conflicts

When a string of characters is matched by two rules, Textmapper reports a conflict. In most cases one of the regular expressions can be rewritten to exclude the conflicting string. Although that is possible in theory, in practice it may lead to enormously long and unreadable definitions. Textmapper has two mechanisms to avoid this problem. The first one is applicable when one of the rules matches only one specific string. I.e. we have a more general and a more specific rule matching the same string. Marking the general one with the _(class)_ attribute tells Textmapper to prefer specific rules over it.

	# 'void' is returned as kw_void, because kw_void is an identifier
	identifier: /[a-zA-Z]+/   (class)
	kw_void: /void/

For all constant regular expressions, Textmapper tries to find a matching _class_ rule. If there are two, a fatal error is reported.

Another solution is to use numerical priorities. The rule with the highest priority value is chosen. When not specified, the priority value is considered to be zero.

	# 'void' is returned as kw_void, because -1 < 0
	identifier: /[a-zA-Z]+/   (-1)
	kw_void: /void/

Intensive usage of priorities can be dangerous, as it prevents Textmapper from detecting potential conflicts as you change the grammar. The conflicts get resolved silently in accordance with priorities, masking the actual problem, which is often a poorly-defined rule.

## Soft terminals

Whenever you need to write a grammar production rule for a specific lexeme value, you face the problem that you have to exclude the string from the original lexeme and handle it as a separate symbol in the grammar. Basically this means replacing all entries of the original terminal with an alternative ```(original | value1 | ... | valueN)```, which makes the grammar more complex and may often introduce unexpected conflicts.

	# that's how we did it before
	INT_wo_01: /[1-9][0-9]+|[2-9]/
	ZERO:   /0/
	ONE:    /1/

	# in the grammar
	number ::= INT_wo_ZERO | ZERO | ONE;

Textmapper introduces the concept of soft terminals to automate and simplify this task. Soft terminals are symbols whose types depend on the grammar context. All soft terminals must have a class symbol. To add a new soft terminal, you mark the original lexeme rule with a _class_ attribute and create a separate soft terminal rule for the constant value. From the lexer point of view, conflicts are automatically resolved in favor of the soft terminal, while in the parser, it is interpreted as its class terminal when that is expected.

	INT:  /[0-9]+/    (class)
	ZERO: /0/         (soft)

	# "0" (returned from the lexer as ZERO) is interpreted as INT here
	input ::= INT ;

A soft terminal symbol behaves like its class terminal symbol in the contexts where the class symbol is expected. Soft terminals therefore inherit all properties from their respective class terminals (attributes, type and semantic action).

	INT (Integer): /[0-9]+/  (class) { .. parsing lexeme value... }

	# ZERO inherits Integer type & semantic action
	ZERO:  /0/    (soft)

	# error: Type should match
	ONE (Long):	  /1/  (soft)

	# replacing the action
	TWO:   /2/     (soft)   { $$ = 2; }

Soft keywords don't contribute to a reserved keywords set, allowing them to be used as plain identifiers.

	ID:      /[a-zA-Z_]+/    (class)
	extends: /extends/       (soft)
	class:   /class/

	# class is a usual keyword, while extends is a soft one
	declaration ::= class ID (extends ID) '{' body '}' ;

The main restriction of soft terminals is that you cannot use them in the same context as their respective class terminals. This will result in an ambiguity as to whether the soft terminal should be interpreted as itself or its class terminal. In addition to LR shift/reduce and reduce/reduce conflicts, soft terminals can introduce two more types of conflicts: _soft shift/reduce_ and _soft reduce/reduce_.

	# sample about conflicts

## Lexer states

Parsing heterogeneous input can require adjusting the set of active lexer rules for different parts of the stream. This can be done by introducing lexer states and mapping rules to them. The lexer can be in only one state at a time. Depending on the state, it uses the appropriate set of rules to match and return the next token. The current state can be changed after a successful token match using transition maps (see below), or from the associated code. There is one predefined state, called **_initial_**, in which the lexer starts reading the stream.

	# after '/*' shift to inComment state
	commentStart: /\/\*/  (space)    { setState(States.inComment); }

States are declared in a mapping clause. In its simple form, a mapping clause is a comma separated list of state names. All rules following the declaration (up to the next mapping clause) are applicable only in the enumerated states.

	[inComment]
	commentText: /*|[^*]+/  (space)
	commentEnd: /\*\// (space)   { setState(States.initial); }

All rules before the first mapping clause fall into the **_initial_** state.

A transition can be declared without associated code by using arrow notation.

	commentStart: /\/\*/  (space, -> inComment)

The mapping clause can contain transitions for each state, which are inherited by rules without explicitly specified transitions.

	# Example: lexer is in newLine state only immediately after \n
	[initial, newLine -> initial]
	NL:   /\n/   (space, -> newLine)

	# no transition, inherits transition from newLine to initial
	ID:  /[a-z]+/

Depending on the state, the same string can be handled in more than one way.

	[newLine] TAB:  /\t/
	[initial] ignoredTab: /\t/  (space)

All specified transitions are applied before the execution of the associated code, so the current state of the lexer can be fine-tuned in the code even when declarative transitions are used.

	leftParen: /\(/   (-> inParentheses)		{ if (!isExpression()) setState(States.initial); }

## Regular expressions

The syntax of regular expressions in Textmapper follows standard practices and is very close to what you know from _perl_ or _flex_. It differs from them slightly, though. There are no capturing groups, lookbehind assertions or non-greedy quantifiers, as they make no sense in lexical patterns. Lookahead assertions are allowed only at the end of the pattern. Notation for character sets partly complies with the [Unicode Technical Standard #18](http://www.unicode.org/reports/tr18/). A brief description of the  syntax used follows.

Characters

	c				matches the character `c'
	.				any character except newline
	\a				alert (bell, '\x07')
	\b				backspace ('\x08')
	\f				form-feed ('\x0c')
	\n				newline (line feed, '\x0a')
	\r				carriage-return ('\x0d')
	\t				tab ('\x09')
	\v				vertical tab ('\x0b')
	\ooo			the character with octal value 0ooo
	\xhh			the character with hexadecimal value 0xhh
	\uhhhh			the character with hexadecimal value 0xhhhh
	\				quote the following non-alphabetic character (to escape brackets, slashes, quantifiers etc.)
	\\				backslash

Character classes

	[abc]			a, b, or c (class)
	[_a-zA-Z]		underscore, a through z or A through Z, inclusive (range)
	[^abc]			any character except a, b, or c (negation)
	\d				a digit: [0-9]
	\D				a non-digit: [^0-9]
	\s				a whitespace character: [ \t\n\v\f\r]
	\S				a non-whitespace character: [^\s]
	\w				a word character: [a-zA-Z_0-9]
	\W				a non-word character: [^\w]
	\p{prop}		any character in the unicode category or block `prop' (see below)
	\P{prop}		a non-prop character: [^\p{prop}]
	\p{Lu}			an uppercase letter (simple category)

Logical operators

	RS				R followed by S (concatenation)
	R|S				either R or S (union)
	(R)				matches an `R' (parentheses are used to override precedence)

Quantifiers

	R?				R, once or not at all
	R*				R, zero or more times
	R+				R, one or more times
	R{n}			R, exactly n times
	R{n,}			R, at least n times
	R{n,m}			R, at least n but not more than m times


Pattern definitions

	{name}			the substitution of the `name' pattern definition

Supported unicode categories (in `\p{xx}`)

	Lu				Letter, uppercase
	Ll				Letter, lowercase
	Lt				Letter, titlecase
	Lm				Letter, modifier
	Lo				Letter, other
	Mn				Mark, nonspacing
	Mc				Mark, spacing combining
	Me				Mark, enclosing
	Nd				Number, decimal digit
	Nl				Number, letter
	No				Number, other
	Pc				Punctuation, connector
	Pd				Punctuation, dash
	Ps				Punctuation, open
	Pe				Punctuation, close
	Pi				Punctuation, initial quote (may behave like Ps or Pe depending on usage)
	Pf				Punctuation, final quote (may behave like Ps or Pe depending on usage)
	Po				Punctuation, other
	Sm				Symbol, math
	Sc				Symbol, currency
	Sk				Symbol, modifier
	So				Symbol, other
	Zs				Separator, space
	Zl				Separator, line
	Zp				Separator, paragraph
	Cc				Other, control
	Cf				Other, format
	Cs				Other, surrogate
	Co				Other, private use
	Cn				Other, not assigned (including non-characters)

Pattern modifiers (in `/pattern/si`)

	s				change `.' to match any character (even a newline)
	i				case-insensitive pattern matching

Unsupported (planned)

	^				the beginning of a line
	$				the end of a line
	{eoi}			an end-of-input (can appear at the end of a pattern only)
	[\w]{-}[A-Z]	difference of two character sets (left associative operator)
	{+}				union
	{&&}			intersection (has lower priority than {+} or {-})
	\Q				quotes all characters until \E
	(?is:R)			match an `R' with the given modifiers (see Pattern modifiers)
	(?-i:R)			turns off modifier

Notes

	[^a-z] matches a newline, unless '\n' is explicitly added into the negated class: [^a-z\n]
	bar* is equivalent to ba(r*), use parentheses to override precedence: (bar)*

## Parser

A parser component, given a stream of tokens, tries to build a parse tree, or reports a syntax error in case of failure. The parser specification consists of EBNF-like production rules, which are used to rewrite the input to the start nonterminal symbol (in a bottom-up manner). There should be at least one grammar rule defining the start symbol (the root of the parse tree), which by convention is called **_input_**.

	# the minimum grammar: input is empty
	input ::= ;

The right-hand side of a rule is a sequence of terminal and nonterminal symbols. Multiple alternative definitions for the same nonterminal can be combined using the vertical bar character ('|').

	input ::= Identifier | IntegerConstant ;

The **_%input_** directive allows you to override the start symbol, or even introduce several start symbols (each gets a separate parse method in the generated code).

	%input start, expr;
	start ::= ID '=' expr ;
	expr ::= IntegerConstant ;

To use an optional symbol (meaning the symbol or an empty string is accepted), the **opt** suffix can be added to the reference. Defining a symbol ending in `opt' is forbidden.

	# a new rule is implicitly added: IDopt ::= ID | ;
	input ::= IDopt ;

## ....

... to be continued


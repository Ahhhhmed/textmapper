${template main-}
${file 'lexer.go'-}
${call go.header-}
${call lexer-}
${end-}
${file 'lexer_tables.go'-}
${call go.header-}
${call lexerTables-}
${end-}
${end}

${template lexer-}
package ${self->go.shortPackage()}

import (
	"strings"
	"unicode/utf8"
${call imports-}
)
${if syntax.lexerStates.size() > 1}
// Lexer states.
const (
${foreach state in syntax.lexerStates-}
	${state->stateId()} = ${state.index}
${end-}
)
${end-}
${if !self->go_token.hasInvalidToken() || opts.reportInvalidRunes}
${call go.errorHandler-}
${end}
// Lexer uses a generated DFA to scan through a utf-8 encoded input string. If
// the string starts with a BOM character, it gets skipped.
type Lexer struct {
	source string
${if !self->go_token.hasInvalidToken() || opts.reportInvalidRunes-}
	err    ErrorHandler
${end-}

	ch          rune // current character, -1 means EOI
	offset      int  // character offset
	tokenOffset int  // last token offset
	line        int  // current line number (1-based)
	tokenLine   int  // last token line
	lineOffset  int  // current line offset
	scanOffset  int  // scanning offset
	value       interface{}

	State int // lexer state, modifiable
${call stateVars-}
}

${if opts.reportInvalidRunes-}
const bom = 0xfeff // byte order mark, permitted as a first character only
${end-}
var bomSeq = "\xef\xbb\xbf"

// Init prepares the lexer l to tokenize source by performing the full reset
// of the internal state.
${if opts.reportInvalidRunes-}
//
// Note that Init may call err once if there is an error in the
// first few characters of the text.
${end-}
func (l *Lexer) Init(source string${if !self->go_token.hasInvalidToken() || opts.reportInvalidRunes}, err ErrorHandler${end}) {
	l.source = source
${if !self->go_token.hasInvalidToken() || opts.reportInvalidRunes-}
	l.err = err
${end-}

	l.ch = 0
	l.offset = 0
	l.tokenOffset = 0
	l.line = 1
	l.tokenLine = 1
	l.lineOffset = 0
	l.scanOffset = 0
	l.State = 0
${call initStateVars-}

	if strings.HasPrefix(source, bomSeq) {
		l.scanOffset += len(bomSeq)
	}

	l.offset = l.scanOffset
	if l.offset < len(l.source) {
		r, w := rune(l.source[l.offset]), 1
		if r >= 0x80 {
			// not ASCII
			r, w = utf8.DecodeRuneInString(l.source[l.offset:])
${if opts.reportInvalidRunes-}
			if r == utf8.RuneError && w == 1 || r == bom {
				l.invalidRune(r, w)
			}
${end-}
		}
		l.scanOffset += w
		l.ch = r
	} else {
		l.ch = -1 // EOI
	}
}

// Next finds and returns the next token in l.source. The source end is
// indicated by Token.EOI.
//
// The token text can be retrieved later by calling the Text() method.
func (l *Lexer) Next() Token {
${call onBeforeNext-}
restart:
	l.tokenLine = l.line
	l.tokenOffset = l.offset

	state := tmStateMap[l.State]
${if self->useCustomMap()-}
	hash := uint32(0)
${end-}
	for state >= 0 {
		var ch int
		switch {
		case l.ch < 0:
			state = int(tmLexerAction[state*tmNumClasses])
			if state == -1 {
${if self->go_token.hasInvalidToken()-}
				return ${self->go_token.invalidTokenName()}  // Unexpected end of input reached
${else-}
				l.err(l.line, l.tokenOffset, l.offset-l.tokenOffset, "Unexpected end of input reached")
${end-}
			}
			continue
		case int(l.ch) < tmRuneClassLen:
			ch = int(tmRuneClass[l.ch])
		default:
${if lex.char2no.length >= 2048-}
			ch = mapRune(l.ch)
${else-}
			ch = 1
${end-}
		}
		state = int(tmLexerAction[state*tmNumClasses+ch])
		if state < -1 {
			break
		}
${if self->useCustomMap()-}
		hash = hash*uint32(31) + uint32(l.ch)
${end-}

		if l.ch == '\n' {
			l.line++
			l.lineOffset = l.offset
		}

		// Scan the next character.
		// Note: the following code is inlined to avoid performance implications.
		l.offset = l.scanOffset
		if l.offset < len(l.source) {
			r, w := rune(l.source[l.offset]), 1
			if r >= 0x80 {
				// not ASCII
				r, w = utf8.DecodeRuneInString(l.source[l.offset:])
${if opts.reportInvalidRunes-}
				if r == utf8.RuneError && w == 1 || r == bom {
					l.invalidRune(r, w)
				}
${end-}
			}
			l.scanOffset += w
			l.ch = r
		} else {
			l.ch = -1 // EOI
		}
	}
	if state >= -2 {
		if state == -1 {
${if self->go_token.hasInvalidToken()-}
			return ${self->go_token.invalidTokenName()}
${else-}
			l.err(l.tokenLine, l.tokenOffset, l.offset-l.tokenOffset, "invalid token")
			goto restart
${end-}
		}
		if state == -2 {
			return EOI
		}
	}

${if self->canInlineLexerRules()-}
	token := Token(-state - 3)
${else-}
	rule := -state - 3
${end-}
${if self->classRules().exists(it|it->classHasInstances())-}
	switch ${self->canInlineLexerRules() ? 'token' : 'rule'} {
${foreach classRule in self->classRules().select(it|it->classHasInstances())-}
${if self->canInlineLexerRules()-}
	case ${classRule.symbol->go_token.tokenName()}:
${else-}
	case ${classRule.index}:
${end-}
		hh := hash&${classRule->rangeSwitchSize() - 1}
		switch hh {
${foreach instance in classRule->classInstances().groupBy(it|util.rangedHash(it.regexp.constantValue, classRule->rangeSwitchSize())).sort(it|util.rangedHash((it is java.util.List ? it[0] : it).regexp.constantValue, classRule->rangeSwitchSize()))-}
${if instance is java.util.List-}
		case ${util.rangedHash(instance[0].regexp.constantValue, classRule->rangeSwitchSize())}:
${foreach i in instance.sort(it|it.regexp.constantValue)-}
${call instanceToRuleIf(i.regexp.constantValue, i)-}
${end-}
${else-}
		case ${util.rangedHash(instance.regexp.constantValue, classRule->rangeSwitchSize())}:
${call instanceToRuleIf(instance.regexp.constantValue, instance)-}
${end-}
${end-}
		}
${end-}
	}
${end-}
${if self->canInlineLexerRules()-}
${if list = syntax.lexerRules.select(r|r->isSpace()).collectUnique(r|r.symbol.index), list.size() > 0}
	switch token {
	case ${list->util.join(', ')}:
		goto restart
	}
${end-}
${else-}

	token := tmToken[rule]
	space := false
${if syntax.lexerRules.exists(r|r->hasActions())-}
	switch rule {
${foreach rule in syntax.lexerRules.select(r|r->hasActions())-}
	case ${rule.index}: // ${rule.symbol.name}: /${rule.regexp}/
${call lexerAction('l.value', 'token') for rule-}
${end-}
	}
${end-}
	if space {
		goto restart
	}
${end-}
${call onAfterNext-}
	return token
}
${if opts.reportInvalidRunes}
func (l *Lexer) invalidRune(r rune, w int) {
	switch r {
	case utf8.RuneError:
		l.err(l.line, l.offset, w, "illegal UTF-8 encoding")
	case bom:
		l.err(l.line, l.offset, w, "illegal byte order mark")
	}
}
${end}
// Pos returns the start and end positions of the last token returned by Next().
func (l *Lexer) Pos() (start, end int) {
	start = l.tokenOffset
	end = l.offset
	return
}

// Line returns the line number of the last token returned by Next().
func (l *Lexer) Line() int {
	return l.tokenLine
}

// Text returns the substring of the input corresponding to the last token.
func (l *Lexer) Text() string {
	return l.source[l.tokenOffset:l.offset]
}

// Value returns the value associated with the last returned token.
func (l *Lexer) Value() interface{} {
	return l.value
}
${end}

${template instanceToRuleIf(val,instanceRule)-}
			if hash == 0x${util.hashHex(val)} && "${util.escape(val)}" == l.source[l.tokenOffset:l.offset] {
${if self->canInlineLexerRules()-}
				token = ${instanceRule.symbol->go_token.tokenName()}
${else-}
				rule = ${instanceRule.index}
${end-}
				break
			}
${end}

${template lexerTables-}
package ${self->go.shortPackage()}

const tmNumClasses = ${lex.nchars}

${if lex.char2no.length >= 2048-}
type mapRange struct {
	lo         rune
	hi         rune
	defaultVal ${self->runeClassType()}
	val        []${self->runeClassType()}
}

func mapRune(c rune) int {
	lo := 0
	hi := len(tmRuneRanges)
	for lo < hi {
		m := lo + (hi-lo)/2
		r := tmRuneRanges[m]
		if c < r.lo {
			hi = m
		} else if c >= r.hi {
			lo = m + 1
		} else {
			i := int(c - r.lo)
			if i < len(r.val) {
				return int(r.val[i])
			}
			return int(r.defaultVal)
		}
	}
	return 1
}

// Latin-1 characters.
var tmRuneClass = []${self->runeClassType()}{
	${util.format(util.head(lex.char2no, 256), 16, 1)},
}

const tmRuneClassLen = 256

var tmRuneRanges = []mapRange{
${foreach r in util.packAsMapRanges(util.tail(lex.char2no, 256), 256)-}
	{${r.lo}, ${r.hi}, ${r.defaultVal}, ${if r.val}[]${self->runeClassType()}{
		${util.format(r.val, 16, 2)},
	}${else}nil${end}},
${end-}
}
${else-}
var tmRuneClass = []${self->runeClassType()}{
	${util.format(lex.char2no, 16, 1)},
}

const tmRuneClassLen = ${lex.char2no.length}
${end-}

var tmStateMap = []int{
	${util.format(lex.groupset, 16, 1)},
}

${if !self->canInlineLexerRules()-}
var tmToken = []Token{
	${util.format(syntax.lexerRuleTokens, 16, 1)},
}

${end-}
${if change = self->canInlineLexerRules() ? syntax.inlineLexerRules(lex.change) : lex.change, true -}
var tmLexerAction = []int${util.bitsForElement(change)}{
	${util.format(change, 16, 1)},
}
${end-}
${end}



${template lexerAction($, symbol)-}
${if self->isSpace()-}
		space = true
${end-}
${if action-}
		${eval action}
${end-}
${end}

${cached query runeClassType() = lex.nchars < 256 ? 'uint8' : lex.nchars < 65536 ? 'uint16' : 'int32' }

${cached query hasActions() = self.action || self->isSpace() }

${cached query isSpace() = self.kindAsText == 'space' && !context.opts.reportTokens.exists(tok|tok == self.symbol)}

${cached query classRules() = syntax.lexerRules.select(x|x.kindAsText == 'class')}

${cached query classHasInstances() = self->classInstances().size() > 0 }

${cached query classInstances() = context.syntax.lexerRules.select(x|x.classRule && x.classRule == self)}

${cached query rangeSwitchSize() = util.rangeSwitchSize(self->classInstances().length)}

${cached query classRuleName() = util.uniqueId(util.toFirstUpper(self.symbol.id), '__classrule__')}

${cached query stateId() = 'State' + util.uniqueId(util.toCamelCase(self.name.replace('-', '_'), true), '__states__')}

${cached query canInlineLexerRules() = syntax.canInlineLexerRules}

${template imports}${end}

${template onAfterNext}${end}
${template onBeforeNext}${end}

${template stateVars}${end}
${template initStateVars}${end}

${cached query useCustomMap() = self->classRules().exists(it|it->classHasInstances())}
